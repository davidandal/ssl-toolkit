{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed212ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffd2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # General\n",
    "    \"training_session\": 1,\n",
    "    \"seed\": 27,\n",
    "\n",
    "    # Pseudo-Labeling Model\n",
    "    \"pre_trained\": True,\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"confidence_threshold\": 0.98,\n",
    "    \"epochs\": 20,\n",
    "\n",
    "    # Dataset\n",
    "    \"labeled_dataset_path\": \"../../datasets/loan.csv\",\n",
    "    \"unlabeled_dataset_path\": \"../../datasets/loan.csv\",\n",
    "    \"validation_set_percentage\": 0.2,\n",
    "    \"batch_size\": 64,\n",
    "\n",
    "    # Tabular input\n",
    "    \"categorical_columns\": [\n",
    "        \"ApplicationDate\", \"EmploymentStatus\", \"EducationLevel\",\n",
    "        \"MaritalStatus\", \"HomeOwnershipStatus\", \"LoanPurpose\"\n",
    "    ],\n",
    "    \"numeric_columns\": [\n",
    "        \"Age\", \"AnnualIncome\", \"CreditScore\", \"Experience\", \"LoanAmount\",\n",
    "        \"LoanDuration\", \"NumberOfDependents\", \"MonthlyDebtPayments\",\n",
    "        \"CreditCardUtilizationRate\", \"NumberOfOpenCreditLines\", \"NumberOfCreditInquiries\",\n",
    "        \"DebtToIncomeRatio\", \"BankruptcyHistory\", \"PreviousLoanDefaults\", \"PaymentHistory\",\n",
    "        \"LengthOfCreditHistory\", \"SavingsAccountBalance\", \"CheckingAccountBalance\",\n",
    "        \"TotalAssets\", \"TotalLiabilities\", \"MonthlyIncome\", \"UtilityBillsPaymentHistory\",\n",
    "        \"JobTenure\", \"NetWorth\", \"BaseInterestRate\", \"InterestRate\",\n",
    "        \"MonthlyLoanPayment\", \"TotalDebtToIncomeRatio\", \"RiskScore\"\n",
    "    ],\n",
    "    \"tabular_target_column\": \"LoanApproved\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8117f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, device, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = loss_function(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c34fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions, all_labels = [], []\n",
    "    total_loss = 0.00\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "            loss = F.cross_entropy(logits, y.long())\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    accuracy = np.mean(np.array(all_predictions) == np.array(all_labels))\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f} | Loss: {total_loss:.4f}\")\n",
    "    \n",
    "    return accuracy, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cabda6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_without_pseudo_labels(model, labeled_loader, validation_loader, unlabeled_loader, device):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "    best_model_path = f\"../../models/pseudo_label/best_model_tabular_{config[\"training_session\"]}.pt\"\n",
    "    best_accuracy = 0.00\n",
    "\n",
    "    # Train on labeled data\n",
    "    for epoch in range(1, config[\"epochs\"] + 1):\n",
    "        print(f\"--- Start of epoch {epoch}! ---\")\n",
    "\n",
    "        train_one_epoch(model, labeled_loader, device, optimizer)\n",
    "\n",
    "        predictions, labels = evaluate(model, validation_loader, device)\n",
    "        validation_accuracy, _ = accuracy_score(labels, predictions)\n",
    "\n",
    "        if validation_accuracy > best_accuracy:\n",
    "            best_accuracy = validation_accuracy\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"✅ Best model saved to {best_model_path} | Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "        print(f\"--- End of epoch {epoch}! ---\")\n",
    "    \n",
    "    # Generate pseudo-labels\n",
    "    model.eval()\n",
    "    pseudo_features, pseudo_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x in unlabeled_loader:\n",
    "            x = x.to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            confidence, predictions = torch.max(probabilities, dim=1)\n",
    "            mask = confidence >= config[\"confidence_threshold\"]\n",
    "\n",
    "            pseudo_features.append(x[mask].cpu())\n",
    "            pseudo_labels.append(predictions[mask].cpu())\n",
    "            \n",
    "    return pseudo_features, pseudo_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5166c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_pseudo(model, labeled_loader, validation_loader, device):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "    best_model_path = f\"../../models/pseudo_label/best_model_tabular_{config[\"training_session\"]}_pseudo.pt\"\n",
    "    best_accuracy = 0.00\n",
    "\n",
    "    # Fine-tune the model with pseudo-labeled data\n",
    "    for epoch in range(1, config[\"epochs\"] + 1):\n",
    "        print(f\"--- Start of epoch {epoch}! ---\")\n",
    "\n",
    "        train_one_epoch(model, labeled_loader, device, optimizer)\n",
    "\n",
    "        predictions, labels = evaluate(model, validation_loader, device)\n",
    "        validation_accuracy, _ = accuracy_score(labels, predictions)\n",
    "\n",
    "        if validation_accuracy > best_accuracy:\n",
    "            best_accuracy = validation_accuracy\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"✅ Best model saved to {best_model_path} | Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "        print(f\"--- End of epoch {epoch}! ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde0b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import token_factory as tf\n",
    "import dataloader_factory as dl\n",
    "import model_factory as md\n",
    "\n",
    "importlib.reload(tf)\n",
    "importlib.reload(dl)\n",
    "importlib.reload(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33112de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from token_factory import token_factory\n",
    "from model_factory import model_factory\n",
    "from dataloader_factory import dataloader_factory, combined_dataloader_factory\n",
    "\n",
    "# Load labeled and unlabeled dataset\n",
    "labeled_dataframe = pd.read_csv(config[\"labeled_dataset_path\"])\n",
    "unlabeled_dataframe = pd.read_csv(config[\"unlabeled_dataset_path\"])\n",
    "\n",
    "# Split labeled dataset into train and validation sets\n",
    "train_dataframe, validation_dataframe = train_test_split(\n",
    "    labeled_dataframe,\n",
    "    test_size=config[\"validation_set_percentage\"],\n",
    "    stratify=labeled_dataframe[\"tabular_target_column\"],\n",
    "    random_state=config[\"seed\"]\n",
    ")\n",
    "\n",
    "# Obtain the tokenizer for tabular inputs\n",
    "tokenizer = token_factory(\n",
    "    categorical_columns=config[\"categorical_columns\"],\n",
    "    numeric_columns=config[\"numeric_columns\"],\n",
    "    target_column=config[\"tabular_target_column\"],\n",
    ")\n",
    "\n",
    "# Fit only on training dataframe\n",
    "tokenizer.fit(train_dataframe)\n",
    "\n",
    "# Tokenize features\n",
    "X_train = tokenizer.transform(train_dataframe)\n",
    "y_train = tokenizer.transform_target(train_dataframe)\n",
    "\n",
    "X_validation = tokenizer.transform(validation_dataframe)\n",
    "y_validation = tokenizer.transform_target(validation_dataframe)\n",
    "\n",
    "X_unlabeled = tokenizer.transform(unlabeled_dataframe)\n",
    "\n",
    "# Create dataloaders\n",
    "loader, unlabeled_loader, validation_loader = dataloader_factory(\n",
    "    X_train=X_train, y_train=y_train, \n",
    "    X_validation=X_validation, y_validation=y_validation, \n",
    "    X_unlabeled=X_unlabeled, batch_size=config[\"batch_size\"]\n",
    ")\n",
    "\n",
    "# Create MLP model\n",
    "input_dim = labeled_dataframe.drop(columns=[config[\"tabular_target_column\"]]).shape[1]\n",
    "num_classes = labeled_dataframe[config[\"tabular_target_column\"]].nunique()\n",
    "model = model_factory(\n",
    "    input_dim=input_dim,\n",
    "    num_classes=num_classes,\n",
    ").to(device)\n",
    "\n",
    "# Train on labeled data and generate pseudolabels\n",
    "X_pseudo, y_pseudo = train_without_pseudo_labels(model, loader, validation_loader, unlabeled_loader, device)\n",
    "\n",
    "# No pseudolabels were generated because model is not confident\n",
    "if len(X_pseudo) == 0:\n",
    "    print(\"No pseudo-labels generated\")\n",
    "    exit(0)\n",
    "\n",
    "# Combine generated pseudolabels with original labeled dataset\n",
    "X_combined = torch.cat([\n",
    "    torch.tensor(X_train, dtype=torch.float32),  \n",
    "    torch.cat(X_pseudo, dim=0)            \n",
    "], dim=0)\n",
    "y_combined = torch.cat([\n",
    "    torch.tensor(y_train, dtype=torch.long),\n",
    "    torch.cat(y_pseudo, dim=0)\n",
    "], dim=0)\n",
    "\n",
    "# Create dataloader for combined dataset\n",
    "labeled_loader = combined_dataloader_factory(X_combined=X_combined, y_combined=y_combined)\n",
    "\n",
    "# Train on labeled data with pseudolabels\n",
    "train_with_pseudo(model, labeled_loader, validation_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
