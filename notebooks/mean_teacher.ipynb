{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed212ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffd2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # General\n",
    "    \"training_session\": 1,\n",
    "\n",
    "    # Model\n",
    "    \"pre_trained\": True,\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"alpha\": 0.99,\n",
    "    \"lambda_u\": 1.0,\n",
    "    \"epochs\": 10,\n",
    "\n",
    "    # Dataset\n",
    "    \"input_type\": \"image\",\n",
    "    \"dataset_path\": \"../datasets/rvl-cdip-kyc\",\n",
    "    \"num_labels_per_class\": 400,\n",
    "    \"batch_size\": 64,\n",
    "\n",
    "    # Image input\n",
    "    \"image_classes\": [\"form\", \"invoice\", \"memo\", \"letter\"],\n",
    "    \"image_size\": 224,\n",
    "\n",
    "    # Text input\n",
    "\n",
    "    # Tabular input\n",
    "    \"categorical_columns\": [\"Cbal\", \"Chist\", \"Cpur\", \"Sbal\", \"MSG\", \"Oparties\", \"Prop\", \"inPlans\", \"Htype\", \"JobType\", \"telephone\", \"foreign\"],\n",
    "    \"numeric_columns\": [\"Cdur\", \"Camt\", \"Edur\", \"InRate\", \"Rdur\", \"age\", \"NumCred\", \"Ndepend\"],\n",
    "    \"target_column\": \"creditScore\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "651b7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ema(student_model, teacher_model):\n",
    "    for student_param, teacher_param in zip(student_model.parameters(), teacher_model.parameters()):\n",
    "        teacher_param.data = config[\"alpha\"] * teacher_param.data + (1 - config[\"alpha\"]) * student_param.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d350fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(student_model, teacher_model, lb_loader, ulb_loader, optimizer, device, epoch):\n",
    "    student_model.train()\n",
    "    teacher_model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for (x_lb, y_lb), (x_ulb_w, x_ulb_s) in zip(lb_loader, ulb_loader):\n",
    "        # Move to device\n",
    "        x_lb, y_lb = x_lb.to(device), y_lb.to(device)\n",
    "        x_ulb_w, x_ulb_s = x_ulb_w.to(device), x_ulb_s.to(device)\n",
    "\n",
    "        # Supervised loss\n",
    "        logits_lb = student_model(x_lb)\n",
    "        loss_sup = F.cross_entropy(logits_lb, y_lb)\n",
    "\n",
    "        # Unsupervised loss (consistency)\n",
    "        with torch.no_grad():\n",
    "            logits_ulb_w = teacher_model(x_ulb_w)\n",
    "            pseudo_labels = torch.softmax(logits_ulb_w, dim=1)\n",
    "\n",
    "        logits_ulb_s = student_model(x_ulb_s)\n",
    "        loss_unsup = F.mse_loss(torch.softmax(logits_ulb_s, dim=1), pseudo_labels)\n",
    "\n",
    "        # Total loss\n",
    "        loss = loss_sup + config[\"lambda_u\"] * loss_unsup\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # EMA update\n",
    "        update_ema(student_model, teacher_model)\n",
    "\n",
    "    print(f'Epoch {epoch} | Total Loss: {total_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e89430b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    acc = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    print(f\"Validation Accuracy: {acc:.4f} | Loss: {total_loss:.4f}\")\n",
    "    return acc, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4464467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mean_teacher(student_model, lb_loader, ulb_loader, val_loader, device=\"cuda\", epochs=10):\n",
    "    teacher_model = copy.deepcopy(student_model)\n",
    "    for param in teacher_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    optimizer = optim.Adam(student_model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_path = f\"../models/mean_teacher/best_model_{config[\"training_session\"]}.pt\"\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_one_epoch(student_model, teacher_model, lb_loader, ulb_loader, optimizer, device, epoch)\n",
    "\n",
    "        val_accuracy, _ = evaluate(student_model, val_loader, device)\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(student_model.state_dict(), best_model_path)\n",
    "            print(f\"✅ Best model saved to {best_model_path} | Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    return student_model, teacher_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecde0b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dundale/Downloads/bpi-ssl/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'utilities.mt_model_factory' from '/Users/dundale/Downloads/bpi-ssl/utilities/mt_model_factory.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import importlib\n",
    "import utilities.mt_token_factory as tf\n",
    "import utilities.mt_dataloader_factory as dl\n",
    "import utilities.mt_model_factory as md\n",
    "\n",
    "importlib.reload(tf)\n",
    "importlib.reload(dl)\n",
    "importlib.reload(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33112de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dundale/Downloads/bpi-ssl/venv/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/dundale/Downloads/bpi-ssl/venv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Total Loss: 20.9808\n",
      "Validation Accuracy: 0.4025 | Loss: 17.0293\n",
      "✅ Best model saved to ../models/mean_teacher/best_model_1.pt | Accuracy: 0.4025\n",
      "Epoch 2 | Total Loss: 9.5580\n",
      "Validation Accuracy: 0.4138 | Loss: 16.0269\n",
      "✅ Best model saved to ../models/mean_teacher/best_model_1.pt | Accuracy: 0.4138\n",
      "Epoch 3 | Total Loss: 5.7303\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if config[\"input_type\"] == \"image\":\n",
    "    from utilities.mt_token_factory import token_factory\n",
    "    from utilities.mt_model_factory import model_factory\n",
    "    from utilities.mt_dataloader_factory import dataloader_factory\n",
    "\n",
    "    base_transform = token_factory(\"image\", image_size=(config[\"image_size\"], config[\"image_size\"]))\n",
    "    \n",
    "    # Create model and dataloaders for image input\n",
    "    model = model_factory(\n",
    "        \"image\", \n",
    "        num_classes=len(config[\"image_classes\"]), \n",
    "        pretrained=config[\"pre_trained\"]\n",
    "    ).to(device)\n",
    "    lb_loader, ulb_loader, val_loader = dataloader_factory(config, base_transform)\n",
    "\n",
    "    # Train Mean Teacher\n",
    "    trained_student, trained_teacher = train_mean_teacher(\n",
    "        model, lb_loader, ulb_loader, val_loader, device, config[\"epochs\"]\n",
    "    )\n",
    "\n",
    "elif config[\"input_type\"] == \"text\":\n",
    "    ...\n",
    "elif config[\"input_type\"] == \"tabular\":\n",
    "    ...\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported input type: {config[\"input_type\"]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
